{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "model = torch.load('./results/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('seq1.0.weight',\n",
       "              tensor([[[[ 4.7540e-01,  8.0394e-01,  6.3910e-01],\n",
       "                        [ 3.7701e-01,  5.6180e-01,  7.7202e-01],\n",
       "                        [-1.4897e-01,  6.9110e-01,  6.3701e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.2420e-01,  4.0017e-01,  3.2791e-01],\n",
       "                        [ 5.7369e-01,  2.4237e-01,  1.2976e-01],\n",
       "                        [-4.6666e-01, -5.8389e-01, -5.2522e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3722e-01,  1.4583e-01,  7.2602e-02],\n",
       "                        [ 1.9934e-01,  2.4869e-01,  4.7347e-01],\n",
       "                        [-2.1201e-01, -4.7502e-01,  2.8655e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0761e-01, -2.3652e-01,  2.3968e-01],\n",
       "                        [-3.1916e-01,  8.6989e-02, -2.9952e-01],\n",
       "                        [-3.1184e-01, -3.1586e-02, -2.3617e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.0698e-01, -7.8754e-02, -3.4249e-01],\n",
       "                        [ 2.5170e-01,  2.1671e-01, -8.2427e-02],\n",
       "                        [-3.2259e-01, -1.9502e-01,  2.1821e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1658e-02,  1.9864e-01,  7.4418e-02],\n",
       "                        [-2.8325e-01, -4.6938e-01, -1.7598e-01],\n",
       "                        [ 1.9861e-01,  3.0440e-01,  5.2070e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.7853e-01,  2.7137e-01, -6.2986e-01],\n",
       "                        [ 4.8677e-01, -1.2878e-01, -5.0352e-01],\n",
       "                        [ 5.0277e-01,  2.7953e-01,  5.0665e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2095e-01, -5.8795e-02,  1.2749e-01],\n",
       "                        [-2.6639e-01, -4.1006e-02,  1.7378e-01],\n",
       "                        [-2.0806e-01,  2.6532e-01,  5.9270e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5389e-01, -2.6880e-01, -2.2735e-01],\n",
       "                        [-1.6221e-01, -2.0247e-01,  2.3731e-01],\n",
       "                        [ 5.6452e-01,  4.0397e-01, -5.2226e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.9265e-01, -1.0909e-01, -2.1180e-02],\n",
       "                        [ 3.1730e-01, -6.9599e-02,  2.3844e-01],\n",
       "                        [-1.3186e-01,  4.2481e-01,  4.8831e-01]]]])),\n",
       "             ('seq1.0.bias',\n",
       "              tensor([ 0.4990, -0.0733,  0.1846,  0.3025,  0.0586,  0.2164, -0.2584,  0.0346,\n",
       "                      -0.2324,  0.3746])),\n",
       "             ('seq2.0.weight',\n",
       "              tensor([[[[ 0.0305,  0.1176,  0.0539],\n",
       "                        [-0.0890, -0.2376,  0.1246],\n",
       "                        [ 0.1798, -0.1951, -0.0259]],\n",
       "              \n",
       "                       [[ 0.0194,  0.0722, -0.0287],\n",
       "                        [ 0.0032, -0.0990, -0.0406],\n",
       "                        [-0.0023, -0.0809, -0.0949]],\n",
       "              \n",
       "                       [[ 0.0501, -0.0153,  0.0013],\n",
       "                        [-0.1003, -0.1101,  0.0800],\n",
       "                        [ 0.1293, -0.0358,  0.0501]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0836,  0.0806,  0.0256],\n",
       "                        [-0.0411, -0.1077, -0.0106],\n",
       "                        [-0.0146,  0.0502,  0.0668]],\n",
       "              \n",
       "                       [[ 0.0364,  0.0224, -0.0271],\n",
       "                        [ 0.0939, -0.0469,  0.0888],\n",
       "                        [ 0.0185,  0.0738, -0.0452]],\n",
       "              \n",
       "                       [[-0.0406,  0.1068,  0.1112],\n",
       "                        [-0.0175, -0.1526,  0.0957],\n",
       "                        [-0.0107,  0.0223, -0.1004]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0230, -0.0904, -0.0306],\n",
       "                        [-0.0548, -0.0607, -0.0789],\n",
       "                        [-0.0791, -0.0714,  0.0742]],\n",
       "              \n",
       "                       [[ 0.0816,  0.0901, -0.0237],\n",
       "                        [-0.0131,  0.0608,  0.0511],\n",
       "                        [-0.0328,  0.0648,  0.0240]],\n",
       "              \n",
       "                       [[ 0.0687,  0.0430,  0.0830],\n",
       "                        [-0.0576, -0.0606,  0.0467],\n",
       "                        [-0.0011,  0.1047,  0.0418]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0531, -0.0387,  0.0042],\n",
       "                        [-0.0244,  0.0083, -0.0984],\n",
       "                        [-0.0344,  0.0740,  0.0218]],\n",
       "              \n",
       "                       [[-0.1044, -0.0133, -0.0883],\n",
       "                        [ 0.0519, -0.0009, -0.0307],\n",
       "                        [ 0.1036,  0.0083,  0.0417]],\n",
       "              \n",
       "                       [[ 0.0025,  0.0388, -0.0786],\n",
       "                        [ 0.0152, -0.0796,  0.0321],\n",
       "                        [ 0.0023, -0.0784, -0.0854]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0501, -0.0159,  0.0147],\n",
       "                        [-0.0466,  0.0534, -0.0869],\n",
       "                        [ 0.0978,  0.1679,  0.1602]],\n",
       "              \n",
       "                       [[ 0.1011, -0.0477,  0.0168],\n",
       "                        [-0.0666, -0.0647,  0.0803],\n",
       "                        [ 0.0554,  0.1957,  0.0267]],\n",
       "              \n",
       "                       [[ 0.1120, -0.0384,  0.0134],\n",
       "                        [-0.0716, -0.0206,  0.0311],\n",
       "                        [-0.0803,  0.0266,  0.2288]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0150, -0.0172,  0.0784],\n",
       "                        [ 0.0676, -0.0804, -0.0645],\n",
       "                        [ 0.0675,  0.0626,  0.0684]],\n",
       "              \n",
       "                       [[ 0.0603, -0.0494, -0.0226],\n",
       "                        [ 0.0092,  0.0049,  0.0688],\n",
       "                        [ 0.0184,  0.1288,  0.0508]],\n",
       "              \n",
       "                       [[-0.0459,  0.0071,  0.0530],\n",
       "                        [-0.0577, -0.0290, -0.0767],\n",
       "                        [-0.0842,  0.1368,  0.1884]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3083, -0.2223,  0.2053],\n",
       "                        [-0.0114, -0.3802,  0.3544],\n",
       "                        [ 0.0033, -0.0944,  0.2153]],\n",
       "              \n",
       "                       [[ 0.0943, -0.0505, -0.1767],\n",
       "                        [-0.0417, -0.0482, -0.1242],\n",
       "                        [-0.0787, -0.1029, -0.1004]],\n",
       "              \n",
       "                       [[ 0.0146, -0.1433,  0.0201],\n",
       "                        [-0.0373, -0.1971,  0.0349],\n",
       "                        [-0.0307,  0.0624, -0.0646]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0370, -0.0847,  0.2559],\n",
       "                        [-0.0729, -0.1063,  0.0482],\n",
       "                        [-0.0110,  0.0364,  0.0390]],\n",
       "              \n",
       "                       [[ 0.0623,  0.0641, -0.1387],\n",
       "                        [ 0.1103,  0.0469, -0.0918],\n",
       "                        [-0.0078, -0.0116, -0.0737]],\n",
       "              \n",
       "                       [[-0.0309, -0.0383, -0.0344],\n",
       "                        [-0.0324, -0.1072,  0.0979],\n",
       "                        [ 0.0372,  0.0690, -0.0046]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2325,  0.1482,  0.1912],\n",
       "                        [ 0.0634,  0.3744, -0.1120],\n",
       "                        [ 0.1574, -0.0009, -0.3563]],\n",
       "              \n",
       "                       [[-0.0604, -0.1380,  0.0584],\n",
       "                        [-0.1544,  0.0613,  0.0964],\n",
       "                        [-0.0820,  0.0128, -0.0421]],\n",
       "              \n",
       "                       [[-0.0962, -0.1168, -0.0498],\n",
       "                        [-0.1747, -0.0684, -0.1037],\n",
       "                        [-0.0398,  0.0225, -0.1851]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0607,  0.1552, -0.1077],\n",
       "                        [ 0.0705,  0.1453, -0.1103],\n",
       "                        [ 0.0804, -0.1558, -0.0366]],\n",
       "              \n",
       "                       [[-0.0376,  0.0414,  0.0109],\n",
       "                        [-0.0378,  0.0152, -0.1396],\n",
       "                        [-0.0505, -0.1674, -0.1258]],\n",
       "              \n",
       "                       [[-0.1148,  0.0687,  0.0631],\n",
       "                        [ 0.0983,  0.0504,  0.0257],\n",
       "                        [-0.0113,  0.0019, -0.1649]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0359, -0.0663,  0.3323],\n",
       "                        [-0.1279, -0.0355,  0.2441],\n",
       "                        [-0.1124,  0.0191,  0.2901]],\n",
       "              \n",
       "                       [[ 0.0594, -0.0423, -0.2270],\n",
       "                        [ 0.0774, -0.1660, -0.0533],\n",
       "                        [ 0.0143, -0.1534, -0.1773]],\n",
       "              \n",
       "                       [[-0.0850, -0.0727,  0.0156],\n",
       "                        [-0.1001, -0.0339, -0.0219],\n",
       "                        [-0.0956,  0.0802,  0.0602]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0017, -0.0054,  0.1186],\n",
       "                        [-0.0710,  0.0037,  0.0656],\n",
       "                        [ 0.0663,  0.1355,  0.0844]],\n",
       "              \n",
       "                       [[ 0.0250, -0.0301, -0.0675],\n",
       "                        [ 0.0405, -0.0607, -0.2418],\n",
       "                        [-0.0320, -0.0716, -0.1614]],\n",
       "              \n",
       "                       [[-0.0393, -0.1404,  0.0557],\n",
       "                        [ 0.0299, -0.0040,  0.0120],\n",
       "                        [-0.0449, -0.0044,  0.1733]]]])),\n",
       "             ('seq2.0.bias',\n",
       "              tensor([-0.0903,  0.0390,  0.0809, -0.1003,  0.0525,  0.0199,  0.0173, -0.0546,\n",
       "                      -0.0190,  0.0198,  0.0451,  0.0100, -0.0999,  0.0400, -0.0893,  0.0651,\n",
       "                      -0.0390, -0.0276,  0.0061,  0.0138])),\n",
       "             ('seq3.0.weight',\n",
       "              tensor([[ 0.0706, -0.0289,  0.0351,  ..., -0.0336,  0.0135, -0.0045],\n",
       "                      [ 0.0580, -0.0953,  0.0076,  ..., -0.1238,  0.0540, -0.0749],\n",
       "                      [ 0.0450, -0.0575,  0.0349,  ..., -0.0004,  0.0211,  0.0350],\n",
       "                      ...,\n",
       "                      [-0.0316, -0.0028,  0.0265,  ..., -0.0714,  0.0306,  0.0184],\n",
       "                      [-0.0079, -0.0222,  0.0565,  ..., -0.0600,  0.0694,  0.0368],\n",
       "                      [ 0.0065,  0.0455, -0.0326,  ...,  0.0609, -0.0192, -0.0375]])),\n",
       "             ('seq3.0.bias',\n",
       "              tensor([-0.0342,  0.0504, -0.0690,  0.0405, -0.0245, -0.0477,  0.0661,  0.0051,\n",
       "                       0.0136, -0.0705,  0.0662,  0.0199, -0.0008,  0.0337, -0.0619, -0.0664,\n",
       "                      -0.0056,  0.0760,  0.0796, -0.0668, -0.0280, -0.0235,  0.0357,  0.0005,\n",
       "                      -0.0258, -0.0523, -0.0523, -0.0290,  0.0301, -0.0673,  0.0151,  0.0195,\n",
       "                      -0.0102, -0.0114,  0.0704,  0.0707,  0.0283, -0.0167,  0.0514,  0.0471,\n",
       "                       0.0695, -0.0199, -0.0645, -0.0185,  0.0206, -0.0661,  0.0265, -0.0742,\n",
       "                      -0.0510,  0.0258])),\n",
       "             ('seq4.0.weight',\n",
       "              tensor([[-5.6796e-02,  4.3810e-02, -9.5029e-02, -5.0745e-02,  8.6083e-02,\n",
       "                       -2.1639e-01,  2.9182e-02,  3.3609e-02,  7.6060e-02,  1.9706e-01,\n",
       "                        1.0814e-01, -1.9234e-01, -4.2786e-02,  2.0848e-02,  3.0000e-01,\n",
       "                       -9.6404e-02,  8.0453e-02, -1.7139e-01, -2.2168e-01,  4.2122e-02,\n",
       "                       -9.9509e-02, -1.6701e-01,  2.6708e-01,  2.9036e-01, -5.0546e-02,\n",
       "                       -1.6089e-02, -6.2049e-02, -2.5334e-02, -2.9051e-04,  2.1383e-01,\n",
       "                        1.1719e-01,  8.1196e-02,  3.4121e-01, -6.3882e-02,  6.3240e-02,\n",
       "                        1.0075e-01,  2.1762e-01, -1.1880e-01, -2.4018e-02, -7.5336e-02,\n",
       "                       -2.5494e-01, -2.3643e-01, -1.0493e-01, -1.2912e-01, -7.8811e-02,\n",
       "                        2.0660e-01, -1.1411e-01,  1.0997e-02,  1.1618e-02,  2.7354e-01],\n",
       "                      [ 2.1191e-01,  3.4512e-01,  9.5801e-02, -6.5328e-02, -3.2152e-01,\n",
       "                        6.3128e-02, -1.9086e-01, -1.2811e-01,  1.3181e-01, -2.0955e-01,\n",
       "                        2.0195e-01, -1.6015e-01,  1.8778e-01, -2.4381e-01, -1.6183e-01,\n",
       "                       -2.3608e-02, -1.3835e-01,  2.1588e-01,  2.0096e-01, -1.3887e-01,\n",
       "                       -1.3744e-02,  2.7238e-01,  1.8493e-02, -1.8711e-01,  8.9142e-02,\n",
       "                       -5.9562e-02,  1.2633e-01,  9.8978e-02,  6.6164e-02, -3.8180e-02,\n",
       "                        8.1565e-03, -2.5892e-02,  1.6014e-01, -1.0325e-01,  1.7351e-01,\n",
       "                        2.0907e-03, -1.1460e-01, -1.3633e-01, -1.0976e-01, -8.7147e-02,\n",
       "                        3.0984e-01,  8.6539e-02, -1.0574e-01,  4.3180e-01, -1.0068e-01,\n",
       "                       -6.7372e-02,  1.3097e-01, -5.6235e-02, -1.2102e-02,  2.3401e-01],\n",
       "                      [-9.1280e-02, -1.9414e-01, -1.3799e-01,  5.5905e-02,  1.5023e-01,\n",
       "                       -2.3103e-01,  2.7172e-01,  8.7427e-02, -7.4979e-02,  2.5447e-01,\n",
       "                        3.9986e-02,  2.6506e-01,  6.3462e-02, -1.9665e-02,  4.2499e-02,\n",
       "                        2.0981e-01, -3.4029e-02,  7.5356e-02, -2.2124e-01,  2.7652e-02,\n",
       "                       -1.2164e-01,  2.9231e-01,  4.5708e-03, -2.4136e-01, -4.6749e-02,\n",
       "                        9.5407e-02, -1.0326e-01,  1.1802e-03, -1.6329e-01,  2.0259e-01,\n",
       "                        4.8207e-02, -4.4956e-02, -1.9088e-01, -2.3366e-01, -1.4876e-02,\n",
       "                        9.7612e-02,  9.0932e-02,  5.0930e-02, -1.2352e-01, -1.3026e-01,\n",
       "                       -4.3353e-02,  1.5136e-02, -1.2433e-01,  3.8675e-01, -4.4398e-04,\n",
       "                        1.7466e-01,  2.2074e-01,  1.1434e-01, -6.5380e-02,  2.2116e-01],\n",
       "                      [ 6.8245e-02,  6.7737e-03, -2.8322e-02, -5.2655e-02,  1.2055e-01,\n",
       "                        2.0627e-01,  2.5073e-01, -2.2011e-01,  1.1819e-02, -1.5945e-01,\n",
       "                       -1.5917e-01,  4.4123e-02,  2.0043e-01,  1.2179e-01,  2.7115e-01,\n",
       "                        2.1542e-01, -9.2644e-03, -1.2548e-01, -1.0092e-02, -1.2505e-01,\n",
       "                       -6.0109e-02,  2.4223e-01, -8.0702e-02, -2.5138e-01, -6.4677e-02,\n",
       "                        6.3367e-02, -1.2330e-01, -5.0867e-02, -3.3909e-01, -1.9459e-01,\n",
       "                       -2.6816e-02,  2.2797e-02, -1.8500e-01,  3.6824e-01, -8.9739e-02,\n",
       "                       -1.0444e-01,  9.5623e-02, -9.1351e-02, -5.6906e-02, -2.1024e-02,\n",
       "                       -2.1120e-01,  2.2445e-01,  2.0331e-01,  1.1806e-01, -6.8506e-02,\n",
       "                        1.8623e-01,  1.8552e-01, -5.1643e-02, -1.0813e-01,  3.8742e-02],\n",
       "                      [ 2.4024e-01, -4.5238e-02, -1.2167e-01, -7.8048e-02,  1.6933e-01,\n",
       "                        1.5238e-01, -1.5443e-01,  3.5998e-01, -1.3739e-01, -2.4725e-02,\n",
       "                       -3.2460e-02,  1.2778e-01, -2.6803e-01,  1.5365e-01, -1.5823e-01,\n",
       "                        1.6039e-01,  1.0140e-01,  1.9933e-01, -6.3216e-02,  1.1378e-01,\n",
       "                       -2.5804e-03, -3.4772e-02,  3.9786e-02,  1.0541e-01,  9.1889e-02,\n",
       "                       -3.1744e-02,  3.7596e-02,  7.4210e-02,  2.4196e-01,  4.7034e-03,\n",
       "                        1.0736e-02,  1.1695e-01, -1.0546e-01, -2.2718e-01, -1.2385e-02,\n",
       "                       -2.5925e-02, -2.9903e-01,  8.5022e-02, -1.4801e-02, -1.0970e-01,\n",
       "                        3.3559e-01,  1.6322e-01,  8.1043e-02, -1.4540e-02,  3.7543e-01,\n",
       "                       -3.6922e-01, -1.9492e-01, -5.7528e-02, -4.2047e-02, -1.0155e-01],\n",
       "                      [-3.2045e-01,  3.5402e-01,  2.8900e-02,  1.2344e-01,  2.2514e-01,\n",
       "                       -1.1335e-01, -3.7327e-02, -1.4977e-01,  5.5300e-03, -1.2572e-02,\n",
       "                       -9.8300e-02, -1.2225e-01,  2.1367e-01,  2.4756e-01, -1.7404e-01,\n",
       "                        1.3473e-01,  1.1614e-01,  1.4855e-01,  7.5315e-02, -1.4414e-02,\n",
       "                        8.3383e-02, -3.6834e-02,  9.4972e-02,  1.8827e-01,  1.3252e-01,\n",
       "                       -6.6283e-02, -1.2830e-01,  8.4921e-02,  1.9014e-01, -3.0391e-01,\n",
       "                       -3.5253e-02, -6.1674e-02, -1.4456e-01,  3.6334e-01, -3.2489e-03,\n",
       "                        9.1054e-02,  2.0906e-01,  6.6773e-02,  5.2361e-02,  3.4186e-02,\n",
       "                       -2.6826e-01,  1.6437e-01,  3.8073e-02, -1.1546e-01, -1.5844e-02,\n",
       "                        7.8614e-02,  1.6309e-01,  2.9550e-02, -7.9507e-02, -1.8950e-01],\n",
       "                      [-1.8698e-01,  3.2397e-02, -7.2340e-03,  8.7531e-02,  1.1844e-01,\n",
       "                       -2.0861e-03, -8.3456e-02,  2.4100e-01, -2.2895e-02,  3.3031e-01,\n",
       "                        2.5404e-01, -2.1464e-01,  1.6325e-01, -2.5703e-01, -8.8909e-02,\n",
       "                        4.0693e-02,  1.1041e-01,  2.4968e-01, -2.2030e-01,  4.3509e-02,\n",
       "                        4.8492e-02, -3.1483e-01, -3.5280e-01,  2.2510e-01, -1.2817e-01,\n",
       "                        1.2909e-01, -8.3561e-02,  3.7212e-02,  2.9076e-01,  1.8347e-01,\n",
       "                       -2.1691e-02, -7.8751e-02, -4.0958e-02, -7.6651e-02, -7.8652e-02,\n",
       "                       -1.1068e-01,  2.4068e-01, -7.4198e-02, -1.6640e-02, -8.4961e-02,\n",
       "                       -7.8347e-02,  7.5705e-02, -1.7757e-01, -1.1897e-01, -1.0522e-01,\n",
       "                       -1.6028e-01, -1.2292e-01,  5.8142e-02,  4.4413e-02, -2.3369e-01],\n",
       "                      [ 8.5792e-02,  1.4451e-01,  2.3513e-02,  1.9686e-01, -2.1742e-01,\n",
       "                       -4.5985e-02,  2.1106e-01, -8.2608e-02, -8.0549e-02, -1.3385e-01,\n",
       "                       -1.5540e-01,  2.7131e-01, -2.8903e-01,  2.3445e-01, -1.8836e-01,\n",
       "                        4.9611e-02, -8.4373e-02, -1.7209e-01,  3.0098e-01, -3.2612e-02,\n",
       "                        9.2839e-02,  3.3792e-01,  2.3490e-01,  1.1614e-01,  1.3017e-02,\n",
       "                       -1.0091e-01, -1.2762e-01, -8.1994e-02, -2.1371e-01, -1.3571e-01,\n",
       "                       -8.8389e-02,  9.2391e-02,  4.7445e-02, -3.9182e-02, -1.3103e-01,\n",
       "                        1.2374e-01, -2.9790e-01, -1.1783e-01,  1.0608e-01,  1.2367e-02,\n",
       "                        2.5808e-01,  2.2670e-01, -1.9553e-01,  2.7578e-02,  2.1121e-01,\n",
       "                        1.9278e-01, -1.6376e-01,  5.0774e-02,  1.3156e-02,  1.3894e-01],\n",
       "                      [ 1.7288e-01, -8.3751e-02,  9.6328e-02, -1.4705e-01,  2.1249e-01,\n",
       "                        1.3733e-01,  3.3639e-01, -2.1115e-01,  1.2231e-01,  9.9757e-02,\n",
       "                        2.1341e-01,  2.0362e-01,  1.3745e-01,  2.3754e-01, -1.3565e-02,\n",
       "                       -8.6711e-02, -1.0907e-01, -1.4704e-02,  1.9004e-02, -1.3499e-02,\n",
       "                        1.1471e-01, -1.0977e-01, -1.7299e-01,  1.1915e-02,  1.4127e-02,\n",
       "                       -1.3843e-01,  4.9430e-02,  7.8451e-02,  2.0161e-01, -1.2898e-01,\n",
       "                       -1.3558e-02, -5.2206e-02,  1.2313e-01,  2.2674e-02, -1.6630e-02,\n",
       "                        5.6809e-02,  2.2113e-01,  4.3598e-02, -7.0113e-03,  3.9194e-02,\n",
       "                       -7.4176e-02, -1.5560e-01,  2.1310e-01,  4.5728e-02,  2.9993e-01,\n",
       "                       -4.6299e-02,  2.2270e-01,  1.2180e-01,  4.6058e-02, -3.5350e-02],\n",
       "                      [-4.9369e-02, -1.8102e-01,  1.3889e-02,  1.6635e-02,  2.5171e-01,\n",
       "                        2.4441e-01, -8.5259e-02,  6.0647e-02, -8.3798e-02, -6.1168e-02,\n",
       "                       -2.0062e-01,  1.9178e-01, -1.5646e-02,  2.2602e-01,  1.9773e-01,\n",
       "                       -1.8578e-01,  8.8285e-02, -3.3872e-01,  2.9425e-01,  7.4324e-02,\n",
       "                        7.5703e-02, -1.5958e-01,  2.0162e-01,  6.8439e-03, -3.3330e-02,\n",
       "                        1.6048e-02, -7.4205e-02, -1.9035e-02, -8.7715e-02,  1.0289e-01,\n",
       "                        7.7392e-02,  5.4830e-02, -4.2772e-02,  3.4897e-01, -5.2755e-02,\n",
       "                        3.7155e-02, -8.3880e-02, -8.6770e-02,  7.9736e-02, -2.0619e-03,\n",
       "                        1.9822e-01,  1.9193e-01,  2.4339e-01, -1.8338e-02,  3.1970e-01,\n",
       "                       -2.2546e-01, -1.1411e-01,  1.1557e-01,  1.4718e-01,  4.2707e-02]])),\n",
       "             ('seq4.0.bias',\n",
       "              tensor([ 0.1065,  0.1758,  0.0160,  0.0511,  0.0188,  0.0083, -0.0694,  0.0839,\n",
       "                       0.0031, -0.0455]))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.Conv2d(1,10,kernel_size=3,padding=1),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.seq2 = nn.Sequential(\n",
    "            nn.Conv2d(10,20,kernel_size=3,padding=1),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.seq3 = nn.Sequential(\n",
    "            nn.Linear(180, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "        )\n",
    "        self.seq4 = nn.Sequential(\n",
    "            nn.Linear(50, 10),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.seq1(x)\n",
    "        x = self.seq2(x)\n",
    "        x = x.view(-1, 180)\n",
    "        x = self.seq3(x)\n",
    "        x = self.seq4(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (seq1): Sequential(\n",
       "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (seq2): Sequential(\n",
       "    (0): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (seq3): Sequential(\n",
       "    (0): Linear(in_features=180, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout2d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (seq4): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307,), (0.3081,))])\n",
    "data_test = datasets.MNIST(root=\"./data/\",\n",
    "                           transform = transform,\n",
    "                           train = False)\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset=data_test,\n",
    "                                               batch_size = 64,\n",
    "                                               shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(data_loader_test)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = net(example_data[0:3])\n",
    "    \n",
    "fig = plt.figure()\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}\".format(\n",
    "        output.data.max(1, keepdim=True)[1][i].item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
